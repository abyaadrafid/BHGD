{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "r50_labelsmooth_finetune_grapheme.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPM61nMaYQV3q05qtX5CSq6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abyaadrafid/BHGD/blob/master/r50_labelsmooth_finetune_grapheme.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkIBAeLWrzpb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from PIL import Image\n",
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, Subset, WeightedRandomSampler, TensorDataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm_notebook\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torchvision import models\n",
        "from collections import Counter\n",
        "from pathlib import Path\n",
        "from sklearn.metrics import confusion_matrix, recall_score\n",
        "import seaborn as sn\n",
        "# !pip install torchsummary \n",
        "# import torchsummary"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZD121Ef_wlbC",
        "colab_type": "code",
        "outputId": "6a477237-9e99-42fd-ab92-fa5c7be77f95",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3bZck25w0rh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train = pd.read_csv('/content/gdrive/My Drive/kaggle/train.csv')\n",
        "df_test = pd.read_csv('/content/gdrive/My Drive/kaggle/test.csv')\n",
        "df_class = pd.read_csv('/content/gdrive/My Drive/kaggle/class_map.csv')\n",
        "df_submission = pd.read_csv('/content/gdrive/My Drive/kaggle/sample_submission.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMnIkzZnw4oR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_tensordataset_from_dfs(parquet_locs, label_loc=None):\n",
        "    ids = []\n",
        "    X = []\n",
        "#     parquet_locs = notebook.tqdm(parquet_locs)\n",
        "    for parquet_loc in parquet_locs:\n",
        "        df = pd.read_parquet(parquet_loc)\n",
        "        ids.extend(df.image_id.tolist())\n",
        "        x = df.iloc[:, 1:].to_numpy(dtype=np.uint8)\n",
        "        del df\n",
        "        X.append(x)\n",
        "    X = np.vstack(X)\n",
        "    X = X.reshape(-1, 1, 137, 236)\n",
        "    X = torch.from_numpy(X)\n",
        "    ids = dict((s,i) for (i,s) in enumerate(ids))\n",
        "    if label_loc is None:\n",
        "        return TensorDataset(X)\n",
        "    else:\n",
        "        graphemes = torch.zeros(X.shape[0], dtype=torch.long)\n",
        "        vowel_diacs = torch.zeros(X.shape[0], dtype=torch.long)\n",
        "        consonant_diacs = torch.zeros(X.shape[0], dtype=torch.long)\n",
        "        lbl_df = pd.read_csv(label_loc)\n",
        "        for row in lbl_df.itertuples():\n",
        "            if row.image_id not in ids:\n",
        "                continue\n",
        "            idx = ids[row.image_id]\n",
        "            graphemes[idx] = row.grapheme_root\n",
        "            vowel_diacs[idx] = row.vowel_diacritic\n",
        "            consonant_diacs[idx] = row.consonant_diacritic\n",
        "        return TensorDataset(X, graphemes, vowel_diacs, consonant_diacs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PAePwNDRw6bx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ds = make_tensordataset_from_dfs(['/content/gdrive/My Drive/kaggle/train_image_data_{}.parquet'.format(i) for i in range(4)], '/content/gdrive/My Drive/kaggle/train.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "dr7q0zi3f8TD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tr_indices, va_indices = train_test_split(list(range(len(ds))), test_size=.1, train_size=.9, random_state=42)#, stratify=ds.tensors[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "uBipocLvf8TF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tr_ds = Subset(ds, tr_indices)\n",
        "va_ds = Subset(ds, va_indices)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "cqTGToIWf8TH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(ds), len(tr_ds), len(va_ds)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "kvGpxtugf8TK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_graphemes, n_vowel_diacs, n_consonant_diacs = len(set(df_train['grapheme_root'])), len(set(df_train['vowel_diacritic'])), len(set(df_train['consonant_diacritic']))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "NbCh4vtYf8TM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_linear_block(in_size, out_size):\n",
        "    block = nn.Sequential(\n",
        "        nn.Linear(in_size, out_size),\n",
        "        nn.ReLU(), \n",
        "        nn.BatchNorm1d(num_features=out_size),\n",
        "        nn.Dropout(0.1)\n",
        "    )\n",
        "    nn.init.xavier_normal_(block[0].weight.data)\n",
        "    nn.init.zeros_(block[0].bias.data)\n",
        "    return block\n",
        "\n",
        "def make_ff_predictor(in_size, intermediate_size, out_size, layer_count):\n",
        "    layers = [make_linear_block(in_size, intermediate_size)]\n",
        "    for i in range(layer_count):\n",
        "        layers.append(make_linear_block(intermediate_size, intermediate_size))\n",
        "    layers.append(make_linear_block(intermediate_size, out_size))\n",
        "    layers = nn.Sequential(*layers)\n",
        "    return layers\n",
        "\n",
        "class BanglaHandwrittenGraphemeNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BanglaHandwrittenGraphemeNN, self).__init__()\n",
        "        base = models.resnet50(pretrained=False)\n",
        "        base.fc = nn.Identity()\n",
        "        self.base = base\n",
        "        feature_size = 2048\n",
        "        self.grapheme_predictor = make_ff_predictor(feature_size, 1024, n_graphemes, 5)\n",
        "        self.vowel_diac_predictor = make_ff_predictor(feature_size, 512, n_vowel_diacs, 3)\n",
        "        self.consonant_diacs = make_ff_predictor(feature_size, 512, n_consonant_diacs, 3)\n",
        "\n",
        "    def convert_to_grayscale(self):\n",
        "        with torch.no_grad():\n",
        "            conv1 = nn.Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
        "            conv1.weight.data = torch.sum(model.base.conv1.weight.data, dim=1, keepdim=True)\n",
        "            self.base.conv1 = conv1\n",
        "            \n",
        "    def freeze(self):\n",
        "        for p in self.base.parameters():\n",
        "            p.requires_grad = False\n",
        "        \n",
        "    def unfreeze(self):\n",
        "        for p in self.base.parameters():\n",
        "            p.requires_grad = True\n",
        "        \n",
        "    def forward(self, x):\n",
        "        features = self.base(x)\n",
        "        g_pred = self.grapheme_predictor(features)\n",
        "        v_pred = self.vowel_diac_predictor(features)\n",
        "        c_pred = self.consonant_diacs(features)\n",
        "        return g_pred, v_pred, c_pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Hy418D5-f8TO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LabelSmoothingLoss(nn.Module):\n",
        "    def __init__(self, classes, smoothing=0.0, dim=-1):\n",
        "        super(LabelSmoothingLoss, self).__init__()\n",
        "        self.confidence = 1.0 - smoothing\n",
        "        self.smoothing = smoothing\n",
        "        self.cls = classes\n",
        "        self.dim = dim\n",
        "\n",
        "    def forward(self, pred, target):\n",
        "        pred = pred.log_softmax(dim=self.dim)\n",
        "        with torch.no_grad():\n",
        "            true_dist = torch.zeros_like(pred)\n",
        "            true_dist.fill_(self.smoothing / (self.cls - 1))\n",
        "            true_dist.scatter_(1, target.data.unsqueeze(1), self.confidence)\n",
        "        return torch.mean(torch.sum(-true_dist * pred, dim=self.dim))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "88CIUoGUf8TP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = BanglaHandwrittenGraphemeNN().to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "fGJ-r3PFf8TR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.convert_to_grayscale()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "A6esSeDWf8TS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.unfreeze()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "41Vo1O_tf8TU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tr_dl = DataLoader(tr_ds, batch_size=64, num_workers=0, pin_memory=True, shuffle=True)\n",
        "va_dl = DataLoader(va_ds, batch_size=64, num_workers=0, pin_memory=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Eo3UA92Hf8TY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gloss = LabelSmoothingLoss(168, smoothing=0.05)\n",
        "vloss = LabelSmoothingLoss(11, smoothing= 0.1)\n",
        "closs = LabelSmoothingLoss(7, smoothing= 0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_ovucLdf8Tb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = [gloss,vloss,closs]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "q1azqrBSf8Td",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = optim.Adam(model.parameters(), lr=5e-5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "H6dsT5WXf8Tf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tr_losses = []\n",
        "va_losses = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "3jGSR0m5f8Tg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mean = lambda l: sum(l) / len(l)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "xhGzwCxLf8Ti",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def run_epochs(num_epochs):\n",
        "  epochs = range(num_epochs)\n",
        "  epochs = tqdm_notebook(range(num_epochs))\n",
        "  for epoch in epochs:\n",
        "      model.train()\n",
        "      count = 0\n",
        "      batches = tr_dl\n",
        "      batches = tqdm_notebook(tr_dl)\n",
        "      for batch in batches:\n",
        "          count += 1\n",
        "          optimizer.zero_grad()\n",
        "          img, g, v, c = batch\n",
        "          img, g, v, c = img.to(device), g.to(device), v.to(device), c.to(device)\n",
        "          img = img / 255.0\n",
        "          g_pred, v_pred, c_pred = model(img)\n",
        "          g_loss = criterion[0](g_pred, g)\n",
        "          v_loss = criterion[1](v_pred, v)\n",
        "          c_loss = criterion[2](c_pred, c)\n",
        "          loss = g_loss + v_loss + c_loss\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          tr_losses.append((g_loss.item(), v_loss.item(), c_loss.item()))\n",
        "      print(mean([sum(t) for t in tr_losses]), mean([t[0] for t in tr_losses]), mean([t[1] for t in tr_losses]), mean([t[2] for t in tr_losses]))\n",
        "      with torch.no_grad():\n",
        "          model.eval()\n",
        "          avg_g_loss = 0.0\n",
        "          avg_v_loss = 0.0\n",
        "          avg_c_loss = 0.0\n",
        "          g_true = []\n",
        "          v_true = []\n",
        "          c_true = []\n",
        "          g_preds = []\n",
        "          v_preds = []\n",
        "          c_preds = []\n",
        "          count = 0\n",
        "          batches = va_dl\n",
        "          batches = tqdm_notebook(va_dl)\n",
        "          for batch in batches:\n",
        "              count += 1\n",
        "              img, g, v, c = batch\n",
        "              img, g, v, c = img.to(device), g.to(device), v.to(device), c.to(device)\n",
        "              img = img / 255.0\n",
        "              g_pred, v_pred, c_pred = model(img)\n",
        "              g_loss = criterion[0](g_pred, g)\n",
        "              v_loss = criterion[1](v_pred, v)\n",
        "              c_loss = criterion[2](c_pred, c)\n",
        "              avg_g_loss += g_loss.item()\n",
        "              avg_v_loss += v_loss.item()\n",
        "              avg_c_loss += c_loss.item()\n",
        "              g_true.extend(g.tolist())\n",
        "              v_true.extend(v.tolist())\n",
        "              c_true.extend(c.tolist())\n",
        "              g_preds.extend(g_pred.argmax(1).tolist())\n",
        "              v_preds.extend(v_pred.argmax(1).tolist())\n",
        "              c_preds.extend(c_pred.argmax(1).tolist())\n",
        "          avg_g_loss /= count\n",
        "          avg_v_loss /= count\n",
        "          avg_c_loss /= count\n",
        "          va_losses.append((avg_g_loss, avg_v_loss, avg_c_loss))\n",
        "          print(sum(va_losses[-1]), va_losses[-1])\n",
        "          print(recall_score(g_true, g_preds, average='macro'))\n",
        "          print(recall_score(v_true, v_preds, average='macro'))\n",
        "          print(recall_score(c_true, c_preds, average='macro'))\n",
        "          print(confusion_matrix(v_true, v_preds))\n",
        "          print(confusion_matrix(c_true, c_preds))\n",
        "          plt.figure(figsize = (20, 20))\n",
        "          sn.heatmap(np.log1p(confusion_matrix(g_true, g_preds)))\n",
        "          plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "alBWBAaTxOE9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_state_dict(torch.load('/content/gdrive/My Drive/r50_labelsmooth.pth'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EtQ_80fbruIp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for p in model.vowel_diac_predictor.parameters():\n",
        "  p.requires_grad=False\n",
        "\n",
        "for p in model.consonant_diacs.parameters():\n",
        "  p.requires_grad=False\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RYHDrsYWsBAi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.freeze()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2vv8HxPxq-x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}