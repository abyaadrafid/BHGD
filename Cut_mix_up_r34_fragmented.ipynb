{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "Cut-mix_up_r34_fragmented.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c0a67def0b2e42cfbced2c039c4343db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2706a916ccd7454a8e398445f5007d32",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_218e86f64e2847228a516507783d007d",
              "IPY_MODEL_6d093fd7e50547938ba9ab599a1f0f1a"
            ]
          }
        },
        "2706a916ccd7454a8e398445f5007d32": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "218e86f64e2847228a516507783d007d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_0515e4eb742a478f859c1f34cb27b4b9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 4,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 4,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d9d06e8cde8440a996416dfe0eb71b05"
          }
        },
        "6d093fd7e50547938ba9ab599a1f0f1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_08e0d88ec49e4e63849185a446be0fb2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 4/4 [01:58&lt;00:00, 29.44s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3d903019863f44e4a5f95fdbbe5a6496"
          }
        },
        "0515e4eb742a478f859c1f34cb27b4b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d9d06e8cde8440a996416dfe0eb71b05": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "08e0d88ec49e4e63849185a446be0fb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3d903019863f44e4a5f95fdbbe5a6496": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abyaadrafid/BHGD/blob/master/Cut_mix_up_r34_fragmented.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "-abjZeq4XB_c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from PIL import Image\n",
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, Subset, WeightedRandomSampler, TensorDataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm_notebook\n",
        "#import torchvision\n",
        "from torchvision import transforms\n",
        "from torchvision import models\n",
        "from collections import Counter\n",
        "from pathlib import Path\n",
        "from sklearn.metrics import confusion_matrix, recall_score\n",
        "import seaborn as sn\n",
        "# !pip install torchsummary \n",
        "# import torchsummary"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "2qmrW6W5XB_i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "a4aaf3b2-6082-4ecb-a977-cf1a54f225b3"
      },
      "source": [
        "print(*torch.__config__.show().split(\"\\n\"), sep=\"\\n\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PyTorch built with:\n",
            "  - GCC 7.3\n",
            "  - Intel(R) Math Kernel Library Version 2019.0.4 Product Build 20190411 for Intel(R) 64 architecture applications\n",
            "  - Intel(R) MKL-DNN v0.20.5 (Git Hash 0125f28c61c1f822fd48570b4c1066f96fcb9b2e)\n",
            "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
            "  - NNPACK is enabled\n",
            "  - Build settings: BLAS=MKL, BUILD_NAMEDTENSOR=OFF, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -fopenmp -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -O2 -fPIC -Wno-narrowing -Wall -Wextra -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Wno-stringop-overflow, DISABLE_NUMA=1, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=True, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "QYmajySTXB_k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fbda451d-d17a-4bf4-9877-983516944bac"
      },
      "source": [
        "torch.get_num_threads()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "CdVyh_58XB_n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.set_num_threads(4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQFy2z7BRbgV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8FtXOouS_T-",
        "colab_type": "code",
        "outputId": "dfd4efaa-e18f-4196-89da-167e98939ab0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "",
        "_uuid": "",
        "trusted": true,
        "id": "bcECQI1gXB_q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train = pd.read_csv('/content/gdrive/My Drive/kaggle/train.csv')\n",
        "df_test = pd.read_csv('/content/gdrive/My Drive/kaggle/test.csv')\n",
        "df_class = pd.read_csv('/content/gdrive/My Drive/kaggle/class_map.csv')\n",
        "df_submission = pd.read_csv('/content/gdrive/My Drive/kaggle/sample_submission.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "_nmfzOY-XB_s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_tensordataset_from_dfs(parquet_locs, label_loc=None):\n",
        "    ids = []\n",
        "    X = []\n",
        "    parquet_locs = tqdm_notebook(parquet_locs)\n",
        "    for parquet_loc in parquet_locs:\n",
        "        df = pd.read_parquet(parquet_loc)\n",
        "        ids.extend(df.image_id.tolist())\n",
        "        x = df.iloc[:, 1:].to_numpy(dtype=np.uint8)\n",
        "        del df\n",
        "        X.append(x)\n",
        "    X = np.vstack(X)\n",
        "    X = X.reshape(-1, 1, 137, 236)\n",
        "    X = torch.from_numpy(X)\n",
        "    ids = dict((s,i) for (i,s) in enumerate(ids))\n",
        "    if label_loc is None:\n",
        "        return TensorDataset(X)\n",
        "    else:\n",
        "        graphemes = torch.zeros(X.shape[0], dtype=torch.long)\n",
        "        vowel_diacs = torch.zeros(X.shape[0], dtype=torch.long)\n",
        "        consonant_diacs = torch.zeros(X.shape[0], dtype=torch.long)\n",
        "        lbl_df = pd.read_csv(label_loc)\n",
        "        for row in lbl_df.itertuples():\n",
        "            if row.image_id not in ids:\n",
        "                continue\n",
        "            idx = ids[row.image_id]\n",
        "            graphemes[idx] = row.grapheme_root\n",
        "            vowel_diacs[idx] = row.vowel_diacritic\n",
        "            consonant_diacs[idx] = row.consonant_diacritic\n",
        "        return TensorDataset(X, graphemes, vowel_diacs, consonant_diacs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "LwxKUzC5XB_u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "c0a67def0b2e42cfbced2c039c4343db",
            "2706a916ccd7454a8e398445f5007d32",
            "218e86f64e2847228a516507783d007d",
            "6d093fd7e50547938ba9ab599a1f0f1a",
            "0515e4eb742a478f859c1f34cb27b4b9",
            "d9d06e8cde8440a996416dfe0eb71b05",
            "08e0d88ec49e4e63849185a446be0fb2",
            "3d903019863f44e4a5f95fdbbe5a6496"
          ]
        },
        "outputId": "02d0c32e-c3bc-4b0a-e79c-4a7e1f82b3e4"
      },
      "source": [
        "ds = make_tensordataset_from_dfs(['/content/gdrive/My Drive/kaggle/train_image_data_{}.parquet'.format(i) for i in range(4)], '/content/gdrive/My Drive/kaggle/train.csv')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c0a67def0b2e42cfbced2c039c4343db",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=4), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "qEZXqmXGXB_w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.imshow(ds[100000][0].permute(1, 2, 0).reshape(137, 236), cmap='gray', vmin=0, vmax=255)\n",
        "ds[100000][1], ds[100000][2], ds[100000][3], ds[100000][0].max(), ds[100000][0].min()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "uGTPk73BXB_y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tr_indices, va_indices = train_test_split(list(range(len(ds))), test_size=.1, train_size=.9, random_state=42)#, stratify=ds.tensors[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "YrLz9retXB_0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tr_ds = Subset(ds, tr_indices)\n",
        "va_ds = Subset(ds, va_indices)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "tSsWZqpZXB_2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(ds), len(tr_ds), len(va_ds)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "jbDlyNj9XB_3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_graphemes, n_vowel_diacs, n_consonant_diacs = len(set(df_train['grapheme_root'])), len(set(df_train['vowel_diacritic'])), len(set(df_train['consonant_diacritic']))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "JjbGup3hXB_5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_linear_block(in_size, out_size):\n",
        "    block = nn.Sequential(\n",
        "        nn.Linear(in_size, out_size), \n",
        "        nn.BatchNorm1d(num_features=out_size),\n",
        "        nn.ReLU(), \n",
        "        nn.Dropout(0.1)\n",
        "    )\n",
        "    nn.init.xavier_normal_(block[0].weight.data)\n",
        "    nn.init.zeros_(block[0].bias.data)\n",
        "    return block\n",
        "\n",
        "def make_ff_predictor(in_size, intermediate_size, out_size, layer_count):\n",
        "    layers = [make_linear_block(in_size, intermediate_size)]\n",
        "    for i in range(layer_count):\n",
        "        layers.append(make_linear_block(intermediate_size, intermediate_size))\n",
        "    layers.append(nn.Linear(intermediate_size, out_size))\n",
        "    layers = nn.Sequential(*layers)\n",
        "    return layers\n",
        "\n",
        "class BanglaHandwrittenGraphemeNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BanglaHandwrittenGraphemeNN, self).__init__()\n",
        "        base = models.resnet34(pretrained=False)\n",
        "        base.fc = nn.Identity()\n",
        "        self.base = base\n",
        "        feature_size = 512\n",
        "        self.grapheme_predictor = make_ff_predictor(feature_size, 384, n_graphemes, 3)\n",
        "        self.vowel_diac_predictor = make_ff_predictor(feature_size, 256, n_vowel_diacs, 2)\n",
        "        self.consonant_diacs = make_ff_predictor(feature_size, 256, n_consonant_diacs, 2)\n",
        "\n",
        "    def convert_to_grayscale(self):\n",
        "        with torch.no_grad():\n",
        "            conv1 = nn.Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
        "            conv1.weight.data = torch.sum(model.base.conv1.weight.data, dim=1, keepdim=True)\n",
        "            self.base.conv1 = conv1\n",
        "            \n",
        "    def freeze(self):\n",
        "        for p in self.base.parameters():\n",
        "            p.requires_grad = False\n",
        "        \n",
        "    def unfreeze(self):\n",
        "        for p in self.base.parameters():\n",
        "            p.requires_grad = True\n",
        "        \n",
        "    def forward(self, x):\n",
        "        features = self.base(x)\n",
        "        g_pred = self.grapheme_predictor(features)\n",
        "        v_pred = self.vowel_diac_predictor(features)\n",
        "        c_pred = self.consonant_diacs(features)\n",
        "        return g_pred, v_pred, c_pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "wBv9_P_7XB_7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = BanglaHandwrittenGraphemeNN().to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "zOfV3mXJXB_8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.convert_to_grayscale()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "SP306pCrXB_-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tr_dl = DataLoader(tr_ds, batch_size=256, num_workers=0, pin_memory=True, shuffle=True)\n",
        "va_dl = DataLoader(va_ds, batch_size=256, num_workers=0, pin_memory=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "32aOeY_eXCAA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = nn.CrossEntropyLoss(reduction='mean')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "hnXn5JzVXCAC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def rand_bbox(size, lam):\n",
        "    W = size[2]\n",
        "    H = size[3]\n",
        "    cut_rat = np.sqrt(1. - lam)\n",
        "    cut_w = np.int(W * cut_rat)\n",
        "    cut_h = np.int(H * cut_rat)\n",
        "\n",
        "    # uniform\n",
        "    cx = np.random.randint(W)\n",
        "    cy = np.random.randint(H)\n",
        "\n",
        "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
        "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
        "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
        "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
        "\n",
        "    return bbx1, bby1, bbx2, bby2\n",
        "\n",
        "def cutmix(data, targets1, targets2, targets3, alpha):\n",
        "    indices = torch.randperm(data.size(0))\n",
        "    shuffled_data = data[indices]\n",
        "    shuffled_targets1 = targets1[indices]\n",
        "    shuffled_targets2 = targets2[indices]\n",
        "    shuffled_targets3 = targets3[indices]\n",
        "\n",
        "    lam = np.random.beta(alpha, alpha)\n",
        "    bbx1, bby1, bbx2, bby2 = rand_bbox(data.size(), lam)\n",
        "    data[:, :, bbx1:bbx2, bby1:bby2] = data[indices, :, bbx1:bbx2, bby1:bby2]\n",
        "    lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (data.size()[-1] * data.size()[-2]))\n",
        "\n",
        "    targets = [targets1, shuffled_targets1, targets2, shuffled_targets2, targets3, shuffled_targets3, lam]\n",
        "    return data, targets\n",
        "\n",
        "def mixup(data, targets1, targets2, targets3, alpha):\n",
        "    indices = torch.randperm(data.size(0))\n",
        "    shuffled_data = data[indices]\n",
        "    shuffled_targets1 = targets1[indices]\n",
        "    shuffled_targets2 = targets2[indices]\n",
        "    shuffled_targets3 = targets3[indices]\n",
        "\n",
        "    lam = np.random.beta(alpha, alpha)\n",
        "    data = data * lam + shuffled_data * (1 - lam)\n",
        "    targets = [targets1, shuffled_targets1, targets2, shuffled_targets2, targets3, shuffled_targets3, lam]\n",
        "\n",
        "    return data, targets\n",
        "\n",
        "\n",
        "def cutmix_criterion(preds1,preds2,preds3, targets):\n",
        "    targets1, targets2,targets3, targets4,targets5, targets6, lam = targets[0], targets[1], targets[2], targets[3], targets[4], targets[5], targets[6]\n",
        "    return lam * criterion(preds1, targets1) + (1 - lam) * criterion(preds1, targets2) + lam * criterion(preds2, targets3) + (1 - lam) * criterion(preds2, targets4) + lam * criterion(preds3, targets5) + (1 - lam) * criterion(preds3, targets6)\n",
        "def mixup_criterion(preds1,preds2,preds3, targets):\n",
        "    targets1, targets2,targets3, targets4,targets5, targets6, lam = targets[0], targets[1], targets[2], targets[3], targets[4], targets[5], targets[6]\n",
        "    return lam * criterion(preds1, targets1) + (1 - lam) * criterion(preds1, targets2) + lam * criterion(preds2, targets3) + (1 - lam) * criterion(preds2, targets4) + lam * criterion(preds3, targets5) + (1 - lam) * criterion(preds3, targets6)\n",
        "\n",
        "def single_cutmix_criterion(preds1,preds2,preds3, targets):\n",
        "    targets1, targets2,targets3, targets4,targets5, targets6, lam = targets[0], targets[1], targets[2], targets[3], targets[4], targets[5], targets[6]\n",
        "    return lam * criterion(preds1, targets1)\n",
        "def single_mixup_criterion(preds1,preds2,preds3, targets):\n",
        "    targets1, targets2,targets3, targets4,targets5, targets6, lam = targets[0], targets[1], targets[2], targets[3], targets[4], targets[5], targets[6]\n",
        "    return lam * criterion(preds1, targets1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "gzUpFRBbXCAD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "wdjYLaF5XCAG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.unfreeze()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "uSu3HuwKXCAJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for p in model.vowel_diac_predictor.parameters():\n",
        "    p.requires_grad = False\n",
        "for p in model.consonant_diacs.parameters():\n",
        "    p.requires_grad = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "CZmXACvRXCAL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tr_losses = []\n",
        "va_losses = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "SdLTke4ZXCAM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mean = lambda l: sum(l) / len(l)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "wky_CgvHXCAO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def single_run_epochs(num_epochs):\n",
        "    epochs = range(num_epochs)\n",
        "    best_score = 0.0\n",
        "    epochs = tqdm_notebook(range(num_epochs))\n",
        "    for epoch in epochs:\n",
        "        model.train()\n",
        "        count = 0\n",
        "        batches = tr_dl\n",
        "        batches = tqdm_notebook(tr_dl)\n",
        "        for batch in batches:\n",
        "            count += 1\n",
        "            optimizer.zero_grad()\n",
        "            img, g, v, c = batch\n",
        "            img, g, v, c = img.to(device), g.to(device), v.to(device), c.to(device)\n",
        "            img = img / 255.0\n",
        "            if np.random.rand()<0.5:\n",
        "                images, targets = mixup(img, g, v, c, 0.4)\n",
        "                g_pred, v_pred, c_pred = model(images)\n",
        "                loss = single_mixup_criterion(g_pred,v_pred,c_pred, targets) \n",
        "            else:\n",
        "                images, targets = cutmix(img, g, v, c, 0.4)\n",
        "                g_pred, v_pred, c_pred = model(images)\n",
        "                loss = single_cutmix_criterion(g_pred,v_pred,c_pred, targets)\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        print(loss.item())\n",
        "        with torch.no_grad():\n",
        "            model.eval()\n",
        "            avg_g_loss = 0.0\n",
        "            avg_v_loss = 0.0\n",
        "            avg_c_loss = 0.0\n",
        "            g_true = []\n",
        "            v_true = []\n",
        "            c_true = []\n",
        "            g_preds = []\n",
        "            v_preds = []\n",
        "            c_preds = []\n",
        "            count = 0\n",
        "            batches = va_dl\n",
        "            batches = notebook.tqdm(va_dl)\n",
        "            for batch in batches:\n",
        "                count += 1\n",
        "                img, g, v, c = batch\n",
        "                img, g, v, c = img.to(device), g.to(device), v.to(device), c.to(device)\n",
        "                img = img / 255.0\n",
        "                g_pred, v_pred, c_pred = model(img)\n",
        "                g_loss = criterion(g_pred, g)\n",
        "                v_loss = criterion(v_pred, v)\n",
        "                c_loss = criterion(c_pred, c)\n",
        "                avg_g_loss += g_loss.item()\n",
        "                avg_v_loss += v_loss.item()\n",
        "                avg_c_loss += c_loss.item()\n",
        "                g_true.extend(g.tolist())\n",
        "                v_true.extend(v.tolist())\n",
        "                c_true.extend(c.tolist())\n",
        "                g_preds.extend(g_pred.argmax(1).tolist())\n",
        "                v_preds.extend(v_pred.argmax(1).tolist())\n",
        "                c_preds.extend(c_pred.argmax(1).tolist())\n",
        "            avg_g_loss /= count\n",
        "            avg_v_loss /= count\n",
        "            avg_c_loss /= count\n",
        "            va_losses.append((avg_g_loss, avg_v_loss, avg_c_loss))\n",
        "            print(sum(va_losses[-1]), va_losses[-1])\n",
        "            gscore = recall_score(g_true, g_preds, average='macro')\n",
        "            vscore = recall_score(v_true, v_preds, average='macro')\n",
        "            cscore = recall_score(c_true, c_preds, average='macro')\n",
        "            avg_score = gscore*0.5+vscore*0.25+cscore*0.25\n",
        "            print(gscore)\n",
        "            print(vscore)\n",
        "            print(cscore)\n",
        "            print(avg_score) \n",
        "            print(confusion_matrix(v_true, v_preds))\n",
        "            print(confusion_matrix(c_true, c_preds))\n",
        "            plt.figure(figsize = (20, 20))\n",
        "            sn.heatmap(np.log1p(confusion_matrix(g_true, g_preds)))\n",
        "            plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "7vS2QcleXCAQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "single_run_epochs(4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "RnCX8xecXCAS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "single_run_epochs(4)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}